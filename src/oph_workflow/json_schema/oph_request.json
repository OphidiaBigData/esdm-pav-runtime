{
	"$schema": "http://json-schema.org/draft-04/schema#",
	"title": "oph_request",
	"description": "Ophidia Request JSON Schema (1.0)",
	"type": "object",
	"properties":
	{
		"name":
		{
			"type": "string",
			"description": "workflow name"
		},
		"author":
		{
			"type": "string",
			"description": "workflow author"
		},
		"abstract":
		{
			"type": "string",
			"description": "workflow description"
		},
		"sessionid":
		{
			"type": "string",
			"description": "session id for the entire workflow"
		},
		"exec_mode":
		{
			"type": "string",
			"enum": ["async", "sync"],
			"default": "async",
			"description": "execution mode for the entire workflow"
		},
		"ncores":
		{
			"type": "string",
			"description": "number of cores for the entire workflow"
		},
		"on_error":
		{
			"type": "string",
			"default": "break",
			"description": "behaviour in case of error. Possible values are: skip (ignore the error, execute descendants), continue (ignore the error, skip descendants), break (abort workflow - default) or repeat N (try to repeat task up to N times before aborting the workflow)"
		},
		"on_exit":
		{
			"type": "string",
			"enum": ["nop", "oph_delete"],
			"default": "nop",
			"description": "operation to be executed on output cubes. Possible values are: nop (no operation) or oph_delete (delete the cube)"
		},
		"run":
		{
			"type": "string",
			"enum": ["yes", "no"],
			"default": "yes",
			"description": "enable submission to analytics framowork. Possible values are: yes or no (simulate workflow execution without submitting tasks really)"
		},
		"cwd":
		{
			"type": "string",
			"description": "current working directory for the entire workflow"
		},
		"cube":
		{
			"type": "string",
			"description": "cube PID for the entire workflow"
		},
		"callback_url":
		{
			"type": "string",
			"description": "callback URL for the entire workflow"
		},
		"output_format":
		{
			"type": "string",
			"enum": ["classic", "compact"],
			"default": "classic",
			"description": "mode to code workflow output. Possible values are: classic or compact (common fields such as session code and workfow id are shown separately)"
		},
		"host_partition":
		{
			"type": "string",
			"description": "name of host partition to be used in the workflow"
		},
		"tasks":
		{
			"type": "array",
			"description": "task list representing the workflow",
			"items":
			{
				"type": "object",
				"description": "workflow task with its properties",
				"properties":
				{
			  		"name":
					{
						"type": "string",
						"description": "unique task name"
					},
					"operator":
					{
						"type": "string",
						"description": "Ophidia operator name"
					},
					"on_error":
					{
						"type": "string",
						"default": "break",
						"description": "behaviour in case of error. Possible values are: skip (ignore the error, execute descendants), continue (ignore the error, skip descendants), break (abort workflow - default) or repeat N (try to repeat task up to N times before aborting the workflow)"
					},
					"on_exit":
					{
						"type": "string",
						"enum": ["nop", "oph_delete"],
						"default": "nop",
						"description": "operation to be executed on output cubes. Possible values are: nop (no operation), delete (delete the cube)"
					},
					"run":
					{
						"type": "string",
						"default": "yes",
						"description": "enable submission to analytics framowork. Possible values are: yes or no (simulate task execution without submitting it really)"
					},
					"arguments":
					{
						"type": "array",
						"description": "list of user-defined operator arguments as key=value pairs",
						"items":
						{
							"type": "string",
							"description": "format to use: keyX=valueX"
						},
						"uniqueItems": true
					},
					"dependencies":
					{
						"type": "array",
						"description": "list of tasks/parameters the current task depends on",
						"items":
						{
							"type": "object",
							"description": "dependency for a specific argument of the current task",
							"properties":
							{
								"argument":
								{
									"type": "string",
									"default": "cube",
									"description": "argument depending on the output of the task 'task'"
								},
								"order":
								{
									"type": "string",
									"default": "0",
									"description": "actual position in case of pipe-separated values for the current argument"
								},
								"task":
								{
									"type": "string",
									"description": "task name the current argument depends on"
								},
								"type":
								{
									"type": "string",
									"enum": ["all","single","embedded"],
									"default": "embedded",
									"description": "type of dependency: all->current argument depends on all the task outputs (1 or more), single->current argument depends on the ONLY 1 task output, embedded->current task has to start ONLY after the execution of the specified task"
								},
								"filter":
								{
									"type": "string",
									"default": "all",
									"description": "filtering expression on the output of the specified task"
								},
								"output_argument":
								{
									"type": "string",
									"default": "cube",
									"description": "output of the task 'task' the current argument depends on"
								},
								"output_order":
								{
									"type": "string",
									"default": "0",
									"description": "actual position in case of pipe-separated values for the task output_argument"
								}
							},
							"required": ["task"],
							"additionalProperties": false
						},
						"uniqueItems": true                      
					}
				},
				"required": ["name", "operator"],
				"additionalProperties": false
			},
			"minItems": 1,
			"uniqueItems": true
		}
	},
	"required": ["name", "author", "abstract", "tasks"],
	"additionalProperties": false
}
